# Aseity Configuration
# Place this file at ~/.config/aseity/config.yaml

default_provider: ollama
default_model: qwen2.5-coder:14b

providers:
  ollama:
    type: openai
    base_url: http://localhost:11434/v1

  vllm:
    type: openai
    base_url: http://localhost:8000/v1

  openai:
    type: openai
    base_url: https://api.openai.com/v1
    api_key: $OPENAI_API_KEY

  anthropic:
    type: anthropic
    api_key: $ANTHROPIC_API_KEY

  google:
    type: google
    api_key: $GEMINI_API_KEY

  huggingface:
    type: openai
    base_url: https://api-inference.huggingface.co/v1
    api_key: $HF_TOKEN

tools:
  auto_approve: []
  # Example: auto_approve: ["bash", "file_read"]
  allowed_commands:
    - git
    - go
    - npm
    - make
    - python
    - cargo
    - docker

# Orchestrator configuration (experimental)
orchestrator:
  enabled: true           # Enable orchestrator integration
  auto_detect: true       # Automatically use orchestrator for complex queries
  parallel: false         # Enable parallel execution
  max_retries: 3          # Maximum retry attempts
  max_steps: 10           # Maximum steps per query
  show_progress: true     # Show execution progress in TUI
